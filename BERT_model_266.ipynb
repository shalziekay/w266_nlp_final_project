{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_model_266.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hreo9vjx7kIt",
        "outputId": "bc92f73a-179c-4766-e256-ae399faf1cf8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR1ETvg078ZV",
        "outputId": "e2c00478-3cc6-4c29-9b6b-14efa2e3ef3d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7Sfv0Fp79Rd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns33m-Ll7zx-"
      },
      "source": [
        "df = pd.read_csv('gdrive/My Drive/Colab Notebooks/train-balanced-sarcasm.csv')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoyjlMo0GYru",
        "outputId": "b797b0d6-f913-49d1-81af-647559ddd880"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1010826, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RklTLZbfGbCN",
        "outputId": "194aecfc-fb8a-4904-f708-4ff8f761b9e7"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label              0\n",
              "comment           53\n",
              "author             0\n",
              "subreddit          0\n",
              "score              0\n",
              "ups                0\n",
              "downs              0\n",
              "date               0\n",
              "created_utc        0\n",
              "parent_comment     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng2FTPneGwKI",
        "outputId": "fb7fa9a0-63aa-464d-8a35-1b1526875892"
      },
      "source": [
        "df = df[df['comment'].notna()]\n",
        "df.isna().sum()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label             0\n",
              "comment           0\n",
              "author            0\n",
              "subreddit         0\n",
              "score             0\n",
              "ups               0\n",
              "downs             0\n",
              "date              0\n",
              "created_utc       0\n",
              "parent_comment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC0OF_h-HMmi",
        "outputId": "d781c069-d4e3-4b9f-dd4e-51d872dbc906"
      },
      "source": [
        "# check label distribution after removing NA\n",
        "df['label'].value_counts()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    505405\n",
              "1    505368\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZJtWutoRw4z"
      },
      "source": [
        "# select a fraction of the data\n",
        "s0 = df.label[df.label.eq(0)].sample(5000).index\n",
        "s1 = df.label[df.label.eq(1)].sample(5000).index \n",
        "\n",
        "df = df.loc[s0.union(s1)]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_xHdxjw9XB3"
      },
      "source": [
        "X_train, temp_text, y_train, temp_labels = train_test_split(df['comment'], df['label'], \n",
        "                                                                    random_state=0, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "X_val, X_test, y_val, y_test = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=0, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZIC9ZYGBbry",
        "outputId": "8ab4acfa-607b-4825-e7bb-3fc62b7cc29d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoLJpizQBdm2",
        "outputId": "10e2000b-0396-4d49-a4ef-2d566a232fa6"
      },
      "source": [
        "X_val.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp2vOvmTBg99",
        "outputId": "178e84c0-6376-498b-dcbc-1fe41801db76"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6QkOTg0BijI"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "# seq_len = [len(i.split()) for i in X_train.values]\n",
        "seq_len = []\n",
        "for i in X_train.values:\n",
        "  seq_len.append(len(str(i).split()))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "4sShSTz8DLxK",
        "outputId": "700a8be7-95a0-453d-9d0d-7834615479cb"
      },
      "source": [
        "pd.Series(seq_len).hist(bins = np.arange(0, 100, 5))\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f80c1883850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPAlJ42wEBia"
      },
      "source": [
        "# set max seq length to 30 based on the histogram above\n",
        "max_seq_len = 30"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXsq6P0ZEVO2"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAqMJ-GlBsx6",
        "outputId": "6e49ff2f-dc34-4f6d-c934-866e4639c2ba"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    X_train.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    X_val.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    X_test.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKfea9pJEN-7"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(y_train.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(y_val.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(y_test.tolist())"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJx1A87XIXAH"
      },
      "source": [
        "# create dataloaders\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5XuPBEgJV5t"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiQPZPVJjQE"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbRO8TcCJpR5"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36ZK1Y9fJpUM"
      },
      "source": [
        "# optimizer from hugging face transformers - define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTDTsE7PJpW2",
        "outputId": "fc329b26-a26e-4720-e73f-a6fc75c7f06e"
      },
      "source": [
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASjAGFDDJpZd"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights = torch.tensor(class_wts, dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs_ZwLYTLCZK"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlVe6q2ZLXKY"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NHDMaB4LX-b",
        "outputId": "213cbe69-8bb1-4ca5-88bf-d788a1aa95f5"
      },
      "source": [
        "# model training\n",
        "\n",
        "\n",
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.697\n",
            "Validation Loss: 0.676\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.680\n",
            "Validation Loss: 0.706\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.677\n",
            "Validation Loss: 0.649\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.665\n",
            "Validation Loss: 0.640\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.657\n",
            "Validation Loss: 0.650\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.652\n",
            "Validation Loss: 0.647\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.656\n",
            "Validation Loss: 0.636\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.650\n",
            "Validation Loss: 0.645\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.651\n",
            "Validation Loss: 0.675\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of    219.\n",
            "  Batch   100  of    219.\n",
            "  Batch   150  of    219.\n",
            "  Batch   200  of    219.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.648\n",
            "Validation Loss: 0.631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSmUlSS6LjUV",
        "outputId": "d500567e-69c8-42ff-950c-4082f42fce7e"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAVI8JH8TLxV"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvva9foXTOQQ",
        "outputId": "00234b62-4dda-4aea-dac5-6402f252cc2f"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.78      0.68       750\n",
            "           1       0.69      0.49      0.58       750\n",
            "\n",
            "    accuracy                           0.64      1500\n",
            "   macro avg       0.65      0.64      0.63      1500\n",
            "weighted avg       0.65      0.64      0.63      1500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "5DuWfgAuTTjF",
        "outputId": "2cbdccc6-ea24-4d0c-ca4a-9621fc9ed679"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>587</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>380</td>\n",
              "      <td>370</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      587  163\n",
              "1      380  370"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7xLL3vwTY8Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_AW4VgwT_kW"
      },
      "source": [
        "Things to improve the model:\n",
        "- Layer specifications\n",
        "- Hyperparameter tuning\n",
        "- How much data to use?\n",
        "- Data preprocessing\n",
        "- sigmoid vs softmax\n",
        "- if there's a different way to write the model code/implement it\n",
        "- ideas from Joachim's BERT video lecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6JAQ9y0UPdj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSbxcJK1Utsg"
      },
      "source": [
        "To do:\n",
        "- watch Joachim's video\n",
        "- understand BERT better\n",
        "- do research to address improving model points above\n",
        "- connect colab to github\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNFx358vVGhp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}