{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistilBERT_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a0f647ecae24b0dbee049f63e93f634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cfc5480ced9d463d8008e3d84e8e562f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85aeb38f5d564846ae864ba99db0e736",
              "IPY_MODEL_d857af6a479e4843bd0492a675af9365"
            ]
          }
        },
        "cfc5480ced9d463d8008e3d84e8e562f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85aeb38f5d564846ae864ba99db0e736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_568d945344d84443a5fb0deef4401502",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_954e3ad60d68400a90beed456a9d55bf"
          }
        },
        "d857af6a479e4843bd0492a675af9365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b03870fbbc3a4270ab6c9c19aae59d50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b544adc1bf854b92a4290a3a799f9232"
          }
        },
        "568d945344d84443a5fb0deef4401502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "954e3ad60d68400a90beed456a9d55bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b03870fbbc3a4270ab6c9c19aae59d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b544adc1bf854b92a4290a3a799f9232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25ab3294660a47a0ae4ee81b51549c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2ac4aa6597094f1dbd30a049bf8beb12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62b8cb11a8534f09ac69c215130a4b22",
              "IPY_MODEL_ff55f72b0b744e57a4fefae7cc2ebd70"
            ]
          }
        },
        "2ac4aa6597094f1dbd30a049bf8beb12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62b8cb11a8534f09ac69c215130a4b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e151d08738474b048f890519dcc9b878",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb45f179c4a943589c3331c6cf8a583c"
          }
        },
        "ff55f72b0b744e57a4fefae7cc2ebd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4975c8f62aec453b8e0acc9e001324ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:36&lt;00:00, 12.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ba526d32ea54b31978f3e5a4f85b6ef"
          }
        },
        "e151d08738474b048f890519dcc9b878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb45f179c4a943589c3331c6cf8a583c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4975c8f62aec453b8e0acc9e001324ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ba526d32ea54b31978f3e5a4f85b6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2340a2e9e3e7452184eb7d4f6546d649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c44475b9a9c344198c5aa72de57abcdd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_04fb264f1de849b7864976436ffa2541",
              "IPY_MODEL_85249d08c364412fbd10ab91298cb3d9"
            ]
          }
        },
        "c44475b9a9c344198c5aa72de57abcdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04fb264f1de849b7864976436ffa2541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ff6b513483741869a5f3d6be72ae92c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eef3a4a5f4864125a7b5d19898a2ba78"
          }
        },
        "85249d08c364412fbd10ab91298cb3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dafde62d069f472a84852de39ef332b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:20&lt;00:00, 1.37B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2322b594bf3410683ef3ce24839dd5a"
          }
        },
        "0ff6b513483741869a5f3d6be72ae92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eef3a4a5f4864125a7b5d19898a2ba78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dafde62d069f472a84852de39ef332b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2322b594bf3410683ef3ce24839dd5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b9ef9fdce1b4f2ea7facf9fbfce707c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb22b795414e4fbb887a385c21b9c172",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2058ed42b4d0471091887a70e31af103",
              "IPY_MODEL_6a6df3287df3428b873127472e5abd4a"
            ]
          }
        },
        "eb22b795414e4fbb887a385c21b9c172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2058ed42b4d0471091887a70e31af103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_428d71082a424c868daeeb2ecdb09118",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 363423424,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 363423424,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f3e61580e4240958978ad82c3986073"
          }
        },
        "6a6df3287df3428b873127472e5abd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_855926bd957f4df190fc9ec3d2d073f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 363M/363M [00:09&lt;00:00, 40.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_755a63227b2e43efa44d891acb2c1a8f"
          }
        },
        "428d71082a424c868daeeb2ecdb09118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f3e61580e4240958978ad82c3986073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "855926bd957f4df190fc9ec3d2d073f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "755a63227b2e43efa44d891acb2c1a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrFK2QV22X9N",
        "outputId": "b7fa98c0-fdf7-43b4-cb3a-129a6977833e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD9MC9OP2ufC",
        "outputId": "cb07cef2-d688-4e9b-ee3c-e89c193578d5"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0MB 18.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 51.4MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=0dd079ff7c1c0f398a136760244adb7ee0329c0e34ec7428c26cff87cb6f2e52\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVK7DgyC201T"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import TFDistilBertModel, DistilBertConfig\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ACV5v9rUw-g"
      },
      "source": [
        "referring to this article: https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx1crfXk3nUn"
      },
      "source": [
        "Read the data in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko-3OTNFmVqV"
      },
      "source": [
        "lav_path = '/content/gdrive/MyDrive/W266Project_Lav_Shalz/train-balanced-sarcasm.csv'\n",
        "shalz_path = '/content/gdrive/MyDrive/Colab Notebooks/train-balanced-sarcasm.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBIqTyoV2w8q"
      },
      "source": [
        "df = pd.read_csv(shalz_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMCrcfn04CE0",
        "outputId": "1ed8ce77-4089-4ce5-b3fb-4bd069d73790"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1010826, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yCgNSLq4D_N",
        "outputId": "b52ca644-e5a0-4828-e040-5d94812dc80a"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label              0\n",
              "comment           53\n",
              "author             0\n",
              "subreddit          0\n",
              "score              0\n",
              "ups                0\n",
              "downs              0\n",
              "date               0\n",
              "created_utc        0\n",
              "parent_comment     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0TcQqEV4Fbd",
        "outputId": "ad52d1ca-7c84-4a6d-854c-e8ed7d35a411"
      },
      "source": [
        "df = df[df['comment'].notna()]\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label             0\n",
              "comment           0\n",
              "author            0\n",
              "subreddit         0\n",
              "score             0\n",
              "ups               0\n",
              "downs             0\n",
              "date              0\n",
              "created_utc       0\n",
              "parent_comment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PUVC-zV4HB_",
        "outputId": "a02cc643-004b-4681-8aa5-cf08c7fb0a9f"
      },
      "source": [
        "# check label distribution after removing NA\n",
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    505405\n",
              "1    505368\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKO0DyLdpGIR"
      },
      "source": [
        "In this notebook, we want to do hyperparameter tuning in order to improve our model. This means that unlike before, we want to be able to use all of the data we have to build the model and then tune the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FbuHcrh4IjN"
      },
      "source": [
        "# # select a fraction of the data\n",
        "# s0 = df.label[df.label.eq(0)].sample(505368).index\n",
        "# s1 = df.label[df.label.eq(1)].sample(505368).index \n",
        "\n",
        "# df = df.loc[s0.union(s1)]\n",
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "9a0f647ecae24b0dbee049f63e93f634",
            "cfc5480ced9d463d8008e3d84e8e562f",
            "85aeb38f5d564846ae864ba99db0e736",
            "d857af6a479e4843bd0492a675af9365",
            "568d945344d84443a5fb0deef4401502",
            "954e3ad60d68400a90beed456a9d55bf",
            "b03870fbbc3a4270ab6c9c19aae59d50",
            "b544adc1bf854b92a4290a3a799f9232",
            "25ab3294660a47a0ae4ee81b51549c86",
            "2ac4aa6597094f1dbd30a049bf8beb12",
            "62b8cb11a8534f09ac69c215130a4b22",
            "ff55f72b0b744e57a4fefae7cc2ebd70",
            "e151d08738474b048f890519dcc9b878",
            "fb45f179c4a943589c3331c6cf8a583c",
            "4975c8f62aec453b8e0acc9e001324ed",
            "8ba526d32ea54b31978f3e5a4f85b6ef",
            "2340a2e9e3e7452184eb7d4f6546d649",
            "c44475b9a9c344198c5aa72de57abcdd",
            "04fb264f1de849b7864976436ffa2541",
            "85249d08c364412fbd10ab91298cb3d9",
            "0ff6b513483741869a5f3d6be72ae92c",
            "eef3a4a5f4864125a7b5d19898a2ba78",
            "dafde62d069f472a84852de39ef332b7",
            "a2322b594bf3410683ef3ce24839dd5a"
          ]
        },
        "id": "lixVjl304KLY",
        "outputId": "9e1c164d-5cec-40b8-c23b-dcd9baa1af06"
      },
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
        "# model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
        "# model.layers\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a0f647ecae24b0dbee049f63e93f634",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25ab3294660a47a0ae4ee81b51549c86",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2340a2e9e3e7452184eb7d4f6546d649",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkG2V4bwCUBt",
        "outputId": "f2a59ec7-6ba5-40f8-cc39-03f6fffb2ea1"
      },
      "source": [
        "# understanding the tokenizer\n",
        "temp_sentence = df[\"comment\"][10]\n",
        "print(temp_sentence)\n",
        "temp_tokens = tokenizer.tokenize(temp_sentence)\n",
        "print(temp_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I think a significant amount would be against spending their tax dollars on other people.\n",
            "['i', 'think', 'a', 'significant', 'amount', 'would', 'be', 'against', 'spending', 'their', 'tax', 'dollars', 'on', 'other', 'people', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKW29H9zDA2Q",
        "outputId": "54ded152-e207-43de-afd8-d0a6fa850e53"
      },
      "source": [
        "tokenizer.batch_encode_plus(temp_tokens,\n",
        "                            max_length=MAX_LENGTH,\n",
        "                            padding='longest', #implements dynamic padding\n",
        "                            truncation=True,\n",
        "                            return_attention_mask=True,\n",
        "                            return_token_type_ids=False\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 1045, 102], [101, 2228, 102], [101, 1037, 102], [101, 3278, 102], [101, 3815, 102], [101, 2052, 102], [101, 2022, 102], [101, 2114, 102], [101, 5938, 102], [101, 2037, 102], [101, 4171, 102], [101, 6363, 102], [101, 2006, 102], [101, 2060, 102], [101, 2111, 102], [101, 1012, 102]], 'attention_mask': [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdZty739Fuke"
      },
      "source": [
        "Let's split the data in train, val, test and then tokenize all of it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BnOEuHk4Pd3"
      },
      "source": [
        "X_train, temp_text, y_train, temp_labels = train_test_split(df['comment'], df['label'], \n",
        "                                                                    random_state=0, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "X_val, X_test, y_val, y_test = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=0, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scgD-GG66RG7"
      },
      "source": [
        "MAX_LENGTH = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "111Gpwj88zl6"
      },
      "source": [
        "def batch_encode(tokenizer, texts, batch_size=256, max_length=MAX_LENGTH):\n",
        "    \"\"\"\"\"\"\"\"\"\n",
        "    A function that encodes a batch of texts and returns the texts'\n",
        "    corresponding encodings and attention masks that are ready to be fed \n",
        "    into a pre-trained transformer model.\n",
        "    \n",
        "    Input:\n",
        "        - tokenizer:   Tokenizer object from the PreTrainedTokenizer Class\n",
        "        - texts:       List of strings where each string represents a text\n",
        "        - batch_size:  Integer controlling number of texts in a batch\n",
        "        - max_length:  Integer controlling max number of words to tokenize in a given text\n",
        "    Output:\n",
        "        - input_ids:       sequence of texts encoded as a tf.Tensor object\n",
        "        - attention_mask:  the texts' attention mask encoded as a tf.Tensor object\n",
        "    \"\"\"\"\"\"\"\"\"\n",
        "    \n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    \n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        inputs = tokenizer.batch_encode_plus(batch,\n",
        "                                             max_length=max_length,\n",
        "                                             padding='longest', #implements dynamic padding\n",
        "                                             truncation=True,\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_token_type_ids=False\n",
        "                                             )\n",
        "        input_ids.extend(inputs['input_ids'])\n",
        "        attention_mask.extend(inputs['attention_mask'])\n",
        "    \n",
        "    \n",
        "    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_mask)\n",
        "    \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ918eOn8zjy"
      },
      "source": [
        "### This cell takes a few minutes to run\n",
        "\n",
        "# Encode X_train\n",
        "X_train_ids, X_train_attention = batch_encode(tokenizer, X_train.tolist())\n",
        "\n",
        "# Encode X_valid\n",
        "X_val_ids, X_val_attention = batch_encode(tokenizer, X_val.tolist())\n",
        "\n",
        "# Encode X_test\n",
        "X_test_ids, X_test_attention = batch_encode(tokenizer, X_test.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "0b9ef9fdce1b4f2ea7facf9fbfce707c",
            "eb22b795414e4fbb887a385c21b9c172",
            "2058ed42b4d0471091887a70e31af103",
            "6a6df3287df3428b873127472e5abd4a",
            "428d71082a424c868daeeb2ecdb09118",
            "2f3e61580e4240958978ad82c3986073",
            "855926bd957f4df190fc9ec3d2d073f3",
            "755a63227b2e43efa44d891acb2c1a8f"
          ]
        },
        "id": "rrHTrnlg8zhu",
        "outputId": "b7e3af4f-8bc6-448c-c534-b3a3f76929d4"
      },
      "source": [
        "DISTILBERT_DROPOUT = 0.2\n",
        "DISTILBERT_ATT_DROPOUT = 0.2\n",
        " \n",
        "# Configure DistilBERT's initialization\n",
        "config = DistilBertConfig(dropout=DISTILBERT_DROPOUT, \n",
        "                          attention_dropout=DISTILBERT_ATT_DROPOUT, \n",
        "                          output_hidden_states=True)\n",
        "                          \n",
        "# The bare, pre-trained DistilBERT transformer model outputting raw hidden-states \n",
        "# and without any specific head on top.\n",
        "distilBERT = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
        "\n",
        "# Make DistilBERT layers untrainable\n",
        "for layer in distilBERT.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b9ef9fdce1b4f2ea7facf9fbfce707c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_layer_norm', 'vocab_projector', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOjuQJjq4-7"
      },
      "source": [
        "Trying to understand the DistilBERT model layers a bit more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INVIjMelquxi",
        "outputId": "ccf7da1a-82bc-4d01-c1cf-50fcc760ac36"
      },
      "source": [
        "distilBERT.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer at 0x7f75c80a1bd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8ol64fyq-lE",
        "outputId": "fd70313b-6289-410a-d3b1-cb77840b26fa"
      },
      "source": [
        "len(distilBERT.layers[0].weights)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkTWvOj6rC8O"
      },
      "source": [
        "We have 100 layers in the model, let's look at the first 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN9m1lf3rGlv",
        "outputId": "d8df60e1-2441-43b5-cfbe-4d6db8390a3d"
      },
      "source": [
        "for layer in range(10):\n",
        "    print(layer)\n",
        "    print('Layer name: \\t', distilBERT.layers[0].weights[layer].name)\n",
        "    print('Layer shape: \\t', distilBERT.layers[0].weights[layer].shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Layer name: \t tf_distil_bert_model/distilbert/embeddings/word_embeddings/weight:0\n",
            "Layer shape: \t (30522, 768)\n",
            "1\n",
            "Layer name: \t tf_distil_bert_model/distilbert/embeddings/position_embeddings/embeddings:0\n",
            "Layer shape: \t (512, 768)\n",
            "2\n",
            "Layer name: \t tf_distil_bert_model/distilbert/embeddings/LayerNorm/gamma:0\n",
            "Layer shape: \t (768,)\n",
            "3\n",
            "Layer name: \t tf_distil_bert_model/distilbert/embeddings/LayerNorm/beta:0\n",
            "Layer shape: \t (768,)\n",
            "4\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._0/attention/q_lin/kernel:0\n",
            "Layer shape: \t (768, 768)\n",
            "5\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._0/attention/q_lin/bias:0\n",
            "Layer shape: \t (768,)\n",
            "6\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._0/attention/k_lin/kernel:0\n",
            "Layer shape: \t (768, 768)\n",
            "7\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._0/attention/k_lin/bias:0\n",
            "Layer shape: \t (768,)\n",
            "8\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._0/attention/v_lin/kernel:0\n",
            "Layer shape: \t (768, 768)\n",
            "9\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._0/attention/v_lin/bias:0\n",
            "Layer shape: \t (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWZR5H-grSmU"
      },
      "source": [
        "Last 5 layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iXo8or0rRuz",
        "outputId": "92319837-6157-49a9-9af1-f17ee0d7a822"
      },
      "source": [
        "for layer in [99, 98, 97, 96, 95]:\n",
        "    print(layer)\n",
        "    print('Layer name: \\t', distilBERT.layers[0].weights[layer].name)\n",
        "    print('Layer shape: \\t', distilBERT.layers[0].weights[layer].shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._5/output_layer_norm/beta:0\n",
            "Layer shape: \t (768,)\n",
            "98\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._5/output_layer_norm/gamma:0\n",
            "Layer shape: \t (768,)\n",
            "97\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._5/ffn/lin2/bias:0\n",
            "Layer shape: \t (768,)\n",
            "96\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._5/ffn/lin2/kernel:0\n",
            "Layer shape: \t (3072, 768)\n",
            "95\n",
            "Layer name: \t tf_distil_bert_model/distilbert/transformer/layer_._5/ffn/lin1/bias:0\n",
            "Layer shape: \t (3072,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goWXf-YwtIps"
      },
      "source": [
        "We see the embedding layer which maps the token id to a 768 dim vector\n",
        "Next is the positional encoding which encodes the 512 BERT input positions. looks right.\n",
        "Layers 5-10 hold the weights and biases for the first self-attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3n6Mfo48zfZ"
      },
      "source": [
        "LAYER_DROPOUT = 0.2\n",
        "LEARNING_RATE = 5e-5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def build_model(transformer, max_length=MAX_LENGTH):\n",
        "    \"\"\"\n",
        "    Template for building a model off of the BERT or DistilBERT architecture\n",
        "    for a binary classification task.\n",
        "    \n",
        "    Input:\n",
        "      - transformer:  a base Hugging Face transformer model object (BERT or DistilBERT)\n",
        "                      with no added classification head attached.\n",
        "      - max_length:   integer controlling the maximum number of encoded tokens \n",
        "                      in a given sequence.\n",
        "    \n",
        "    Output:\n",
        "      - model:        a compiled tf.keras.Model with added classification layers \n",
        "                      on top of the base pre-trained model architecture.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define weight initializer with a random seed to ensure reproducibility\n",
        "    weight_initializer = tf.keras.initializers.GlorotNormal(seed=RANDOM_STATE) \n",
        "    \n",
        "    # Define input layers\n",
        "    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n",
        "                                            name='input_ids', \n",
        "                                            dtype='int32')\n",
        "    input_attention_layer = tf.keras.layers.Input(shape=(max_length,), \n",
        "                                                  name='input_attention', \n",
        "                                                  dtype='int32')\n",
        "    \n",
        "    # DistilBERT outputs a tuple where the first element at index 0\n",
        "    # represents the hidden-state at the output of the model's last layer.\n",
        "    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n",
        "    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n",
        "    \n",
        "    # We only care about DistilBERT's output for the [CLS] token, \n",
        "    # which is located at index 0 of every encoded sequence.  \n",
        "    # Splicing out the [CLS] tokens gives us 2D data.\n",
        "    cls_token = last_hidden_state[:, 0, :]\n",
        "    \n",
        "    ##                                                 ##\n",
        "    ## Define additional dropout and dense layers here ##\n",
        "    ##                                                 ##\n",
        "    \n",
        "    # Define a single node that makes up the output layer (for binary classification)\n",
        "    output = tf.keras.layers.Dense(1, \n",
        "                                   activation='sigmoid',\n",
        "                                   kernel_initializer=weight_initializer,  \n",
        "                                   kernel_constraint=None,\n",
        "                                   bias_initializer='zeros'\n",
        "                                   )(cls_token)\n",
        "    \n",
        "    # Define the model\n",
        "    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=LEARNING_RATE), \n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgq1d8x7GIo6",
        "outputId": "8da37703-4e5f-4ad6-c264-8110556ac148"
      },
      "source": [
        "model = build_model(distilBERT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f7626466ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f7626466ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f7641d17c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f7641d17c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ12ibAH8zY7",
        "outputId": "e6fee038-27a1-4d93-8c03-efe4d33b521f"
      },
      "source": [
        "EPOCHS = 6\n",
        "BATCH_SIZE = 64\n",
        "NUM_STEPS = len(X_train.index) // BATCH_SIZE\n",
        "\n",
        "# Train the model\n",
        "train_history1 = model.fit(\n",
        "    x = [X_train_ids, X_train_attention],\n",
        "    y = y_train.to_numpy(),\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    steps_per_epoch = NUM_STEPS,\n",
        "    validation_data = ([X_val_ids, X_val_attention], y_val.to_numpy()),\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "11055/11055 - 869s - loss: 0.6538 - accuracy: 0.6120 - val_loss: 0.6299 - val_accuracy: 0.6437\n",
            "Epoch 2/6\n",
            "11055/11055 - 861s - loss: 0.6352 - accuracy: 0.6382 - val_loss: 0.6207 - val_accuracy: 0.6545\n",
            "Epoch 3/6\n",
            "11055/11055 - 861s - loss: 0.6301 - accuracy: 0.6442 - val_loss: 0.6157 - val_accuracy: 0.6595\n",
            "Epoch 4/6\n",
            "11055/11055 - 861s - loss: 0.6274 - accuracy: 0.6468 - val_loss: 0.6127 - val_accuracy: 0.6627\n",
            "Epoch 5/6\n",
            "11055/11055 - 861s - loss: 0.6253 - accuracy: 0.6492 - val_loss: 0.6103 - val_accuracy: 0.6650\n",
            "Epoch 6/6\n",
            "11055/11055 - 862s - loss: 0.6240 - accuracy: 0.6513 - val_loss: 0.6083 - val_accuracy: 0.6658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLFpuUKF8zWN",
        "outputId": "b48dd612-8ed5-40c7-8004-0a5af624c5e5"
      },
      "source": [
        "FT_EPOCHS = 4\n",
        "BATCH_SIZE = 64\n",
        "NUM_STEPS = len(X_train.index)\n",
        "\n",
        "# Unfreeze distilBERT layers and make available for training\n",
        "for layer in distilBERT.layers:\n",
        "    layer.trainable = True\n",
        "    \n",
        "# Recompile model after unfreezing\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "train_history2 = model.fit(\n",
        "    x = [X_train_ids, X_train_attention],\n",
        "    y = y_train.to_numpy(),\n",
        "    epochs = FT_EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    steps_per_epoch = NUM_STEPS,\n",
        "    validation_data = ([X_val_ids, X_val_attention], y_val.to_numpy()),\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2830164 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "707541/707541 - 8453s - loss: 0.4618 - accuracy: 0.7783 - val_loss: 0.5063 - val_accuracy: 0.7696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHhs-Y5t8fE2"
      },
      "source": [
        "All of the above code was run the full data using random parameters. We get a training accuracy of 77.83% and a validation accuracy of 76.96%, which are good signs we are not overfitting.\n",
        "\n",
        "Next, let's try changing the model architecture slightly (adding some dense layers) and hyperparameter tuning the model. Based on some research, the parameters that lead to the biggest change in accuracy are: learning rate, dropout, and batch size so I am going to focus on these parameters. It may also be good to try adding more dense/dropout layers to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlHOongwz-TJ"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_sY-k0iApVk"
      },
      "source": [
        "## Add additional layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ULtBTBuHpu0"
      },
      "source": [
        "# resetting some of the global parameters here\n",
        "LAYER_DROPOUT = 0.2\n",
        "LEARNING_RATE = 5e-5\n",
        "RANDOM_STATE = 42\n",
        "DISTILBERT_DROPOUT = 0.2\n",
        "DISTILBERT_ATT_DROPOUT = 0.2\n",
        "MAX_LENGTH = 30\n",
        "L2REG = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5KDpgozAk66"
      },
      "source": [
        "def build_model2(transformer, max_length=MAX_LENGTH, l2reg = L2REG, dropout_rate = LAYER_DROPOUT):\n",
        "    \"\"\"\n",
        "    Template for building a model off of the BERT or DistilBERT architecture\n",
        "    for a binary classification task.\n",
        "    \n",
        "    Input:\n",
        "      - transformer:  a base Hugging Face transformer model object (BERT or DistilBERT)\n",
        "                      with no added classification head attached.\n",
        "      - max_length:   integer controlling the maximum number of encoded tokens \n",
        "                      in a given sequence.\n",
        "    \n",
        "    Output:\n",
        "      - model:        a compiled tf.keras.Model with added classification layers \n",
        "                      on top of the base pre-trained model architecture.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define weight initializer with a random seed to ensure reproducibility\n",
        "    weight_initializer = tf.keras.initializers.GlorotNormal(seed=RANDOM_STATE) \n",
        "    \n",
        "    # Define input layers\n",
        "    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n",
        "                                            name='input_ids', \n",
        "                                            dtype='int32')\n",
        "    input_attention_layer = tf.keras.layers.Input(shape=(max_length,), \n",
        "                                                  name='input_attention', \n",
        "                                                  dtype='int32')\n",
        "    \n",
        "    # DistilBERT outputs a tuple where the first element at index 0\n",
        "    # represents the hidden-state at the output of the model's last layer.\n",
        "    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n",
        "    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n",
        "    \n",
        "    # We only care about DistilBERT's output for the [CLS] token, \n",
        "    # which is located at index 0 of every encoded sequence.  \n",
        "    # Splicing out the [CLS] tokens gives us 2D data.\n",
        "    cls_token = last_hidden_state[:, 0, :]\n",
        "    \n",
        "    ##                                                 ##\n",
        "    ## Define additional dropout and dense layers here ##\n",
        "    ##                                                 ##\n",
        "    dense = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer= tf.keras.regularizers.l2(l2reg))(cls_token)\n",
        "    dropout= tf.keras.layers.Dropout(dropout_rate)(dense)\n",
        "    \n",
        "    # Define a single node that makes up the output layer (for binary classification)\n",
        "    output = tf.keras.layers.Dense(1, \n",
        "                                   activation='sigmoid',\n",
        "                                   kernel_initializer=weight_initializer,  \n",
        "                                   kernel_constraint=None,\n",
        "                                   bias_initializer='zeros'\n",
        "                                   )(dropout)\n",
        "    \n",
        "    # Define the model\n",
        "    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=LEARNING_RATE), \n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "    # inps = Input(shape = (max_len,), dtype='int64')\n",
        "    # masks= Input(shape = (max_len,), dtype='int64')\n",
        "    # dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
        "    # dense = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
        "    # dropout= Dropout(0.5)(dense)\n",
        "    # pred = Dense(num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
        "    # model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
        "    # print(model.summary())\n",
        "    # return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xHlfFUJI74f",
        "outputId": "5c45cc49-3d5a-4301-f9e5-3525229a3ac6"
      },
      "source": [
        "model2 = build_model2(distilBERT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb3dea35ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb3dea35ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fb3fa2e6c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fb3fa2e6c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_OFU9zRZqvj"
      },
      "source": [
        "EPOCHS = 6\n",
        "BATCH_SIZE = 64\n",
        "NUM_STEPS = len(X_train.index) // BATCH_SIZE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q95uv8l2Jgku",
        "outputId": "151150fb-f9ab-405a-ecc5-fbd14fdb7f2e"
      },
      "source": [
        "\n",
        "# Train the model\n",
        "train_history3 = model2.fit(\n",
        "    x = [X_train_ids, X_train_attention],\n",
        "    y = y_train.to_numpy(),\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    steps_per_epoch = NUM_STEPS,\n",
        "    validation_data = ([X_val_ids, X_val_attention], y_val.to_numpy()),\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "11055/11055 - 2234s - loss: 0.7305 - accuracy: 0.8047 - val_loss: 0.5110 - val_accuracy: 0.7629\n",
            "Epoch 2/6\n",
            "11055/11055 - 2226s - loss: 0.3899 - accuracy: 0.8259 - val_loss: 0.5051 - val_accuracy: 0.7584\n",
            "Epoch 3/6\n",
            "11055/11055 - 2226s - loss: 0.3469 - accuracy: 0.8492 - val_loss: 0.5824 - val_accuracy: 0.7495\n",
            "Epoch 4/6\n",
            "11055/11055 - 2223s - loss: 0.3076 - accuracy: 0.8692 - val_loss: 0.5959 - val_accuracy: 0.7534\n",
            "Epoch 5/6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jihnv3zQYKvI"
      },
      "source": [
        "with additional dense + dropout layers\n",
        "\n",
        "\n",
        "11055/11055 - 2234s - loss: 0.7305 - accuracy: 0.8047 - val_loss: 0.5110 - val_accuracy: 0.7629\n",
        "Epoch 2/6\n",
        "11055/11055 - 2226s - loss: 0.3899 - accuracy: 0.8259 - val_loss: 0.5051 - val_accuracy: 0.7584\n",
        "Epoch 3/6\n",
        "11055/11055 - 2226s - loss: 0.3469 - accuracy: 0.8492 - val_loss: 0.5824 - val_accuracy: 0.7495\n",
        "Epoch 4/6\n",
        "11055/11055 - 2223s - loss: 0.3076 - accuracy: 0.8692 - val_loss: 0.5959 - val_accuracy: 0.7534\n",
        "Epoch 5/6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbEHs1bjZ2Gp"
      },
      "source": [
        "FT_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbywJ9C-JHZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d635e61-0025-47c4-8360-e3869750222a"
      },
      "source": [
        "# Unfreeze distilBERT layers and make available for training\n",
        "for layer in distilBERT.layers:\n",
        "    layer.trainable = True\n",
        "    \n",
        "# Recompile model after unfreezing\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "train_history4 = model2.fit(\n",
        "    x = [X_train_ids, X_train_attention],\n",
        "    y = y_train.to_numpy(),\n",
        "    epochs = FT_EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    steps_per_epoch = NUM_STEPS,\n",
        "    validation_data = ([X_val_ids, X_val_attention], y_val.to_numpy()),\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "11055/11055 - 2283s - loss: 0.3801 - accuracy: 0.8299 - val_loss: 0.5387 - val_accuracy: 0.7676\n",
            "Epoch 2/10\n",
            "11055/11055 - 2290s - loss: 0.3486 - accuracy: 0.8474 - val_loss: 0.5328 - val_accuracy: 0.7625\n",
            "Epoch 3/10\n",
            "11055/11055 - 2283s - loss: 0.3183 - accuracy: 0.8637 - val_loss: 0.5681 - val_accuracy: 0.7627\n",
            "Epoch 4/10\n",
            "11055/11055 - 2287s - loss: 0.2878 - accuracy: 0.8786 - val_loss: 0.5962 - val_accuracy: 0.7601\n",
            "Epoch 5/10\n",
            "11055/11055 - 2280s - loss: 0.2621 - accuracy: 0.8912 - val_loss: 0.6502 - val_accuracy: 0.7570\n",
            "Epoch 6/10\n",
            "11055/11055 - 2286s - loss: 0.2371 - accuracy: 0.9028 - val_loss: 0.6628 - val_accuracy: 0.7553\n",
            "Epoch 7/10\n",
            "11055/11055 - 2286s - loss: 0.2152 - accuracy: 0.9131 - val_loss: 0.7298 - val_accuracy: 0.7532\n",
            "Epoch 8/10\n",
            "11055/11055 - 2287s - loss: 0.1963 - accuracy: 0.9218 - val_loss: 0.7284 - val_accuracy: 0.7539\n",
            "Epoch 9/10\n",
            "11055/11055 - 2285s - loss: 0.1788 - accuracy: 0.9290 - val_loss: 0.7987 - val_accuracy: 0.7509\n",
            "Epoch 10/10\n",
            "11055/11055 - 2283s - loss: 0.1641 - accuracy: 0.9355 - val_loss: 0.8397 - val_accuracy: 0.7494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvTTPSr09nmm",
        "outputId": "e5511616-a646-4cdc-c20a-706e815cac6c"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_attention (InputLayer)    [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
            "                                                                 input_attention[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 768)          0           tf_distil_bert_model[0][7]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          393728      tf.__operators__.getitem[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            513         dropout_19[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 66,757,121\n",
            "Trainable params: 66,757,121\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4guV1gaKUFyd"
      },
      "source": [
        "# save this model\n",
        "# !mkdir -p distilbert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "lP9nMIkAd-E8",
        "outputId": "5dc1dc26-93dd-4ae6-eec2-c42461c915c3"
      },
      "source": [
        "import torch\n",
        "torch.save(model2, 'model2_saved')\n",
        "\n",
        "# saved_model = torch.load('path/to/model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-99b1b503fc3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model2_saved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# saved_model = torch.load('path/to/model')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWAlDVF9YHJF"
      },
      "source": [
        "# hyper parameter values to try\n",
        "lr_vals = [5e-7, 5e-6, 5e-5, 5e-4, 5e-3, 5e-2, 5e-1] \n",
        "EPOCHS = 6\n",
        "BATCH_SIZE = 64\n",
        "NUM_STEPS = len(X_train.index) // BATCH_SIZE\n",
        "\n",
        "\n",
        "LEARNING_RATE_TUNE0 = lr_vals[0]\n",
        "\n",
        "def build_model_tune0(transformer, max_length=MAX_LENGTH, l2reg = L2REG, dropout_rate = LAYER_DROPOUT, lr = LEARNING_RATE_TUNE0):\n",
        "    \"\"\"\n",
        "    Template for building a model off of the BERT or DistilBERT architecture\n",
        "    for a binary classification task.\n",
        "    \n",
        "    Input:\n",
        "      - transformer:  a base Hugging Face transformer model object (BERT or DistilBERT)\n",
        "                      with no added classification head attached.\n",
        "      - max_length:   integer controlling the maximum number of encoded tokens \n",
        "                      in a given sequence.\n",
        "    \n",
        "    Output:\n",
        "      - model:        a compiled tf.keras.Model with added classification layers \n",
        "                      on top of the base pre-trained model architecture.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define weight initializer with a random seed to ensure reproducibility\n",
        "    weight_initializer = tf.keras.initializers.GlorotNormal(seed=RANDOM_STATE) \n",
        "    \n",
        "    # Define input layers\n",
        "    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n",
        "                                            name='input_ids', \n",
        "                                            dtype='int32')\n",
        "    input_attention_layer = tf.keras.layers.Input(shape=(max_length,), \n",
        "                                                  name='input_attention', \n",
        "                                                  dtype='int32')\n",
        "    \n",
        "    # DistilBERT outputs a tuple where the first element at index 0\n",
        "    # represents the hidden-state at the output of the model's last layer.\n",
        "    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n",
        "    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n",
        "    \n",
        "    # We only care about DistilBERT's output for the [CLS] token, \n",
        "    # which is located at index 0 of every encoded sequence.  \n",
        "    # Splicing out the [CLS] tokens gives us 2D data.\n",
        "    cls_token = last_hidden_state[:, 0, :]\n",
        "    \n",
        "    ##                                                 ##\n",
        "    ## Define additional dropout and dense layers here ##\n",
        "    ##                                                 ##\n",
        "    dense = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer= tf.keras.regularizers.l2(l2reg))(cls_token)\n",
        "    dropout= tf.keras.layers.Dropout(dropout_rate)(dense)\n",
        "    \n",
        "    # Define a single node that makes up the output layer (for binary classification)\n",
        "    output = tf.keras.layers.Dense(1, \n",
        "                                   activation='sigmoid',\n",
        "                                   kernel_initializer=weight_initializer,  \n",
        "                                   kernel_constraint=None,\n",
        "                                   bias_initializer='zeros'\n",
        "                                   )(dropout)\n",
        "    \n",
        "    # Define the model\n",
        "    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=lr), \n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UmhklWkMZc0",
        "outputId": "58c90795-cf31-4e0a-8b31-8206cb75b9da"
      },
      "source": [
        "hyperparam_models = []\n",
        "train_histories = []\n",
        "\n",
        "for lr in lr_vals:\n",
        "  model3 = build_model_tune0(distilBERT, max_length=MAX_LENGTH, l2reg = L2REG, dropout_rate = LAYER_DROPOUT, lr = lr)\n",
        "\n",
        "  train_history3 = model3.fit(\n",
        "    x = [X_train_ids, X_train_attention],\n",
        "    y = y_train.to_numpy(),\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    steps_per_epoch = NUM_STEPS,\n",
        "    validation_data = ([X_val_ids, X_val_attention], y_val.to_numpy()),\n",
        "    verbose=2\n",
        ")\n",
        "  \n",
        "  hyperparam_models.append(model3)\n",
        "  train_histories.append(train_history3)\n",
        "\n",
        "  print(\"Learning Rate: \", lr)\n",
        "  print()\n",
        "  print(model3.summary())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f8e50d33ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f8e50d33ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f8e6c5e4c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f8e6c5e4c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convertWARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "\n",
            "Epoch 1/6\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "11055/11055 - 871s - loss: 6.2524 - accuracy: 0.5203 - val_loss: 5.6675 - val_accuracy: 0.5885\n",
            "Epoch 2/6\n",
            "11055/11055 - 867s - loss: 5.1588 - accuracy: 0.5595 - val_loss: 4.6573 - val_accuracy: 0.6148\n",
            "Epoch 3/6\n",
            "11055/11055 - 873s - loss: 4.2299 - accuracy: 0.5814 - val_loss: 3.8060 - val_accuracy: 0.6243\n",
            "Epoch 4/6\n",
            "11055/11055 - 872s - loss: 3.4535 - accuracy: 0.5938 - val_loss: 3.1005 - val_accuracy: 0.6289\n",
            "Epoch 5/6\n",
            "11055/11055 - 869s - loss: 2.8154 - accuracy: 0.6017 - val_loss: 2.5265 - val_accuracy: 0.6314\n",
            "Epoch 6/6\n",
            "11055/11055 - 869s - loss: 2.3005 - accuracy: 0.6086 - val_loss: 2.0686 - val_accuracy: 0.6345\n",
            "Learning Rate:  5e-07\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_attention (InputLayer)    [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
            "                                                                 input_attention[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 768)          0           tf_distil_bert_model[0][7]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          393728      tf.__operators__.getitem[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            513         dropout_19[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 66,757,121\n",
            "Trainable params: 394,241\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/6\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "11055/11055 - 874s - loss: 3.1214 - accuracy: 0.5941 - val_loss: 1.1826 - val_accuracy: 0.6368\n",
            "Epoch 2/6\n",
            "11055/11055 - 868s - loss: 0.8834 - accuracy: 0.6261 - val_loss: 0.7391 - val_accuracy: 0.6489\n",
            "Epoch 3/6\n",
            "11055/11055 - 867s - loss: 0.7175 - accuracy: 0.6324 - val_loss: 0.6803 - val_accuracy: 0.6512\n",
            "Epoch 4/6\n",
            "11055/11055 - 868s - loss: 0.6835 - accuracy: 0.6354 - val_loss: 0.6610 - val_accuracy: 0.6536\n",
            "Epoch 5/6\n",
            "11055/11055 - 868s - loss: 0.6703 - accuracy: 0.6374 - val_loss: 0.6521 - val_accuracy: 0.6546\n",
            "Epoch 6/6\n",
            "11055/11055 - 868s - loss: 0.6634 - accuracy: 0.6389 - val_loss: 0.6467 - val_accuracy: 0.6552\n",
            "Learning Rate:  5e-06\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_attention (InputLayer)    [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
            "                                                                 input_attention[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None, 768)          0           tf_distil_bert_model[1][7]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          393728      tf.__operators__.getitem_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 512)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            513         dropout_20[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 66,757,121\n",
            "Trainable params: 394,241\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/6\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "11055/11055 - 874s - loss: 0.9514 - accuracy: 0.6282 - val_loss: 0.6422 - val_accuracy: 0.6487\n",
            "Epoch 2/6\n",
            "11055/11055 - 869s - loss: 0.6489 - accuracy: 0.6403 - val_loss: 0.6281 - val_accuracy: 0.6607\n",
            "Epoch 3/6\n",
            "11055/11055 - 867s - loss: 0.6411 - accuracy: 0.6459 - val_loss: 0.6259 - val_accuracy: 0.6589\n",
            "Epoch 4/6\n",
            "11055/11055 - 866s - loss: 0.6362 - accuracy: 0.6500 - val_loss: 0.6172 - val_accuracy: 0.6723\n",
            "Epoch 5/6\n",
            "11055/11055 - 868s - loss: 0.6332 - accuracy: 0.6534 - val_loss: 0.6174 - val_accuracy: 0.6681\n",
            "Epoch 6/6\n",
            "11055/11055 - 869s - loss: 0.6306 - accuracy: 0.6560 - val_loss: 0.6131 - val_accuracy: 0.6753\n",
            "Learning Rate:  5e-05\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_attention (InputLayer)    [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
            "                                                                 input_attention[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_2 (Sli (None, 768)          0           tf_distil_bert_model[2][7]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 512)          393728      tf.__operators__.getitem_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 512)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            513         dropout_21[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 66,757,121\n",
            "Trainable params: 394,241\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/6\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "11055/11055 - 879s - loss: 0.6919 - accuracy: 0.6226 - val_loss: 0.6373 - val_accuracy: 0.6535\n",
            "Epoch 2/6\n",
            "11055/11055 - 872s - loss: 0.6508 - accuracy: 0.6359 - val_loss: 0.6312 - val_accuracy: 0.6553\n",
            "Epoch 3/6\n",
            "11055/11055 - 873s - loss: 0.6462 - accuracy: 0.6406 - val_loss: 0.6316 - val_accuracy: 0.6574\n",
            "Epoch 4/6\n",
            "11055/11055 - 874s - loss: 0.6442 - accuracy: 0.6425 - val_loss: 0.6334 - val_accuracy: 0.6528\n",
            "Epoch 5/6\n",
            "11055/11055 - 874s - loss: 0.6442 - accuracy: 0.6418 - val_loss: 0.6188 - val_accuracy: 0.6708\n",
            "Epoch 6/6\n",
            "11055/11055 - 871s - loss: 0.6433 - accuracy: 0.6419 - val_loss: 0.6263 - val_accuracy: 0.6599\n",
            "Learning Rate:  0.0005\n",
            "\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_attention (InputLayer)    [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
            "                                                                 input_attention[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_3 (Sli (None, 768)          0           tf_distil_bert_model[3][7]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 512)          393728      tf.__operators__.getitem_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 512)          0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            513         dropout_22[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 66,757,121\n",
            "Trainable params: 394,241\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/6\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "11055/11055 - 880s - loss: 0.6977 - accuracy: 0.5073 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/6\n",
            "11055/11055 - 874s - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 3/6\n",
            "11055/11055 - 873s - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/6\n",
            "11055/11055 - 874s - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wg5XI1uTFl1"
      },
      "source": [
        "# had to rerun some of them\n",
        "lr_vals = [5e-4, 5e-3, 5e-2, 5e-1]\n",
        "\n",
        "\n",
        "hyperparam_models1 = []\n",
        "train_histories1 = []\n",
        "\n",
        "for lr in lr_vals:\n",
        "  model3 = build_model_tune0(distilBERT, max_length=MAX_LENGTH, l2reg = L2REG, dropout_rate = LAYER_DROPOUT, lr = lr)\n",
        "\n",
        "  train_history3 = model3.fit(\n",
        "    x = [X_train_ids, X_train_attention],\n",
        "    y = y_train.to_numpy(),\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    steps_per_epoch = NUM_STEPS,\n",
        "    validation_data = ([X_val_ids, X_val_attention], y_val.to_numpy()),\n",
        "    verbose=2\n",
        ")\n",
        "  \n",
        "  hyperparam_models1.append(model3)\n",
        "  train_histories1.append(train_history3)\n",
        "\n",
        "  print(\"Learning Rate: \", lr)\n",
        "  print()\n",
        "  print(model3.summary())\n",
        "\n",
        "\n",
        "\n",
        "# which learning rate was the best? \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFT07yn862Xz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}